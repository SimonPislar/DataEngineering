{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_session = SparkSession\\\n",
    "        .builder\\\n",
    "        .master(\"spark://192.168.2.250:7077\") \\\n",
    "        .appName(\"Part_B_Simon_Pislar_A3\")\\\n",
    "        .config(\"spark.dynamicAllocation.enabled\", True)\\\n",
    "        .config(\"spark.dynamicAllocation.shuffleTracking.enabled\",True)\\\n",
    "        .config(\"spark.shuffle.service.enabled\", False)\\\n",
    "        .config(\"spark.dynamicAllocation.executorIdleTimeout\",\"30s\")\\\n",
    "        .config(\"spark.executor.cores\",2)\\\n",
    "        .config(\"spark.driver.port\",9999)\\\n",
    "        .config(\"spark.blockManager.port\",10005)\\\n",
    "        .getOrCreate()\n",
    "\n",
    "# RDD  API\n",
    "spark_context = spark_session.sparkContext\n",
    "\n",
    "spark_context.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = spark_session.read.csv(\"hdfs://192.168.2.250:9000/parking-citations.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "effe4de9e989818d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.printSchema()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e3f48a19fd9cf110"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "row_count = df.count()\n",
    "print(f\"Number of rows: {row_count}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9896a8c527d800b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "partition_count = df.rdd.getNumPartitions()\n",
    "print(f\"Number of partitions: {partition_count}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa499e21331c03fa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = df.drop('VIN', 'Latitude', 'Longitude')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf331bed8cc33ce6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import FloatType\n",
    "\n",
    "df = df.withColumn(\"FineAmount\", col(\"FineAmount\").cast(FloatType()))\n",
    "max_fine_amount = df.agg({\"FineAmount\": \"max\"}).collect()[0][0]\n",
    "count_max_fine = df.where(col(\"FineAmount\") == max_fine_amount).count()\n",
    "\n",
    "print(f\"Maximum fine amount: {max_fine_amount}\")\n",
    "print(f\"Number of fines with maximum amount: {count_max_fine}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "403571c190730401"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc\n",
    "\n",
    "df.groupBy(\"Make\").count().orderBy(desc(\"count\")).show(20)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1bb15c7da0e8aeed"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
